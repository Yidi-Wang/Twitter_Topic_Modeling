{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import config #put config.py in the same directory\n",
    "import pyodbc\n",
    "import json\n",
    "import tweepy\n",
    "from pylib import utils\n",
    "from pylib.simplesqlserver import SimpleSQLServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_debug_ = False\n",
    "_online_ = True # read from online sources\n",
    "_writedb_ = True # whether write outputs to database.\n",
    "max_tweets = 1000\n",
    "\n",
    "utils.enable_utf_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_fields = {\n",
    "    'id':'tweet_id',\n",
    "    'text':'tweet_text',\n",
    "    'source':'source',\n",
    "    'retweet_count':'retweet_count',    \n",
    "    'in_reply_to_status_id':'reply_tweet_id',\n",
    "    'in_reply_to_user_id':'reply_user_id',\n",
    "    'favorite_count':'favorite_count',\n",
    "    'created_at' : 'created_at',\n",
    "    'place' : 'place_json',\n",
    "    'retweeted' : 'retweet',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to users table\n",
    "user_fields = {\n",
    "    'name':'name',\n",
    "    'screen_name':'screen_name',\n",
    "    'id':'user_id',\n",
    "    'created_at':'created_at',\n",
    "    'followers_count':'followers_count',\n",
    "    'friends_count':'friends_count',\n",
    "    'favourites_count':'favourites_count',\n",
    "    'statuses_count':'statuses_count',\n",
    "    'description':'description',\n",
    "    'time_zone':'timezone',\n",
    "    'utc_offset':'utc_offset',\n",
    "    'verified':'verified',\n",
    "    'lang':'language',\n",
    "    'location':'location',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to hashtags table\n",
    "hashtags_fields = {\n",
    "    'text':'text',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to mentions table\n",
    "mentions_fields = {\n",
    "    'id':'target_user_id',\n",
    "    'screen_name':'screen_name',\n",
    "    'name':'name',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fields(source, fields):\n",
    "    # given a source and a destination dict, copy the fields from source to destination according to the mapping provided by fields.  \n",
    "    dest={}    \n",
    "    if not isinstance(source, dict):\n",
    "        print \"source is not a dict\" + type(source)\n",
    "\n",
    "    for field in fields:\n",
    "        if source.get(field):\n",
    "            dest[fields[field]]=source[field]\n",
    "    return dest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomStreamListener(tweepy.StreamListener): \n",
    "    counter = 0               \n",
    "    def on_data(self, raw_tweet):\n",
    "        # on_data provides data in the raw json string\n",
    "        try:    \n",
    "            # record the time of event\n",
    "            capture_date = utils.mysql_time()            \n",
    "            tweet = json.loads(raw_tweet)\n",
    "            if tweet.get('delete'):\n",
    "                return True # skip delete tweet  \n",
    "            elif tweet.get('lang') != 'en':\n",
    "                return True # skip non english tweet\n",
    "                \n",
    "            tweet_data = {}\n",
    "            user_data = {}\n",
    "            hashtags_data = []\n",
    "            mentions_data = []\n",
    "            \n",
    "            # retrieve and store tweet_data    \n",
    "            tweet_data.update(get_fields(tweet,tweet_fields))\n",
    "            \n",
    "            # check for required fields\n",
    "            if not tweet_data.get('tweet_id'):\n",
    "                if _debug_:\n",
    "                    # save the tweet for debugging\n",
    "                    utils.dump_json(tweet,'debug/tweet.txt')\n",
    "                print('No tweet id')\n",
    "                return True  # discard this tweet \n",
    "            \n",
    "            # fields that need special processing\n",
    "            if tweet_data.get('created_at'):\n",
    "                tweet_data['created_at'] = utils.utc_to_mysql_time(tweet_data['created_at'])\n",
    "            if tweet.get('coordinates'):\n",
    "                if tweet['coordinates'].get('coordinates'):\n",
    "                    tweet_data['geo_long'] = tweet['coordinates']['coordinates'][0]\n",
    "                    tweet_data['geo_lat'] = tweet['coordinates']['coordinates'][1]\n",
    "            if tweet.get('retweeted_status'):\n",
    "                tweet_data['retweet'] = 1\n",
    "            else:\n",
    "                tweet_data['retweet'] = 0\n",
    "                    \n",
    "            # retrieve and store user_data.          \n",
    "            if tweet.get('user'):\n",
    "                user_data.update(get_fields(tweet['user'],user_fields))    \n",
    "                if not user_data.get('user_id'):\n",
    "                    if _debug_:\n",
    "                        utils.dump_json(tweet,'debug/tweet%s.txt'%tweet_data.get('tweet_id'))\n",
    "                    print('No tweet user id')\n",
    "                    return True  # discard this tweet            \n",
    "                if user_data.get('created_at'):\n",
    "                    user_data['created_at']=utils.utc_to_mysql_time(user_data['created_at'])\n",
    "\n",
    "            # retrieve and store hashtag, user_mention and url data.   \n",
    "            if tweet.get('entities'): \n",
    "                if tweet['entities'].get('hashtags'): \n",
    "                    for hashtag in tweet['entities']['hashtags']:\n",
    "                        hashtag_data = {'tweet_id':tweet_data.get('tweet_id')}\n",
    "                        hashtag_data.update(get_fields(hashtag, hashtags_fields))\n",
    "                        hashtags_data.append(hashtag_data)\n",
    "                if tweet['entities'].get('user_mentions'):    \n",
    "                    for mention in tweet['entities']['user_mentions']:  # extract every user_mention from the user_mentions list\n",
    "                        mention_data = {'tweet_id':tweet_data.get('tweet_id'), 'source_user_id':user_data.get('user_id')}\n",
    "                        mention_data.update(get_fields(mention,mentions_fields))\n",
    "                        mentions_data.append(mention_data)             \n",
    "\n",
    "            # enrichment    \n",
    "            if tweet_data: \n",
    "                tweet_data['user_id'] = user_data.get('user_id')\n",
    "                tweet_data['capture_date']=capture_date\n",
    "           \n",
    "            if user_data:\n",
    "                user_data['capture_date']=capture_date\n",
    "                user_data['period'] = capture_date[:10]\n",
    "         \n",
    "            print \"%s %i tweet id:%s\"%(capture_date, self.counter, tweet_data.get('tweet_id'))\n",
    "                        \n",
    "            # write tweet_data and user_data into database\n",
    "            for table, data in (('users',user_data),('tweets',tweet_data)):\n",
    "                if data: \n",
    "                    if _writedb_:\n",
    "                        print \"%i %s inserted\"%(db.insert(table, data), table)\n",
    "                    else:\n",
    "                        print table\n",
    "                        print data\n",
    "            \n",
    "            # write hashtag, user_mention and url data into database at once\n",
    "            for table, data in (('hashtags', hashtags_data), ('mentions', mentions_data)):\n",
    "                if data: \n",
    "                    if _writedb_:\n",
    "                        print \"%i %s inserted\"%(db.inserts(table, data), table)                        \n",
    "                    else:\n",
    "                        print table\n",
    "                        print data\n",
    "                        \n",
    "            # count the number of collected tweets\n",
    "            self.counter += 1          \n",
    "            if self.counter >= max_tweets:\n",
    "                print 'target number of tweets =%s have reached'%self.counter\n",
    "                return False\n",
    "        \n",
    "        except Exception, e:\n",
    "            if _debug_:\n",
    "                # write the tweet to local disk for debugging\n",
    "                utils.dump_json(tweet,'debug/tweet.txt')\n",
    "                raise \n",
    "            else:\n",
    "                pass # ignore errors\n",
    "   \n",
    "    def on_error(self, status_code):\n",
    "        print \"Got an API error with status code %s\" % str(status_code)\n",
    "        return True     # continue to listening\n",
    "    \n",
    "    def on_timeout(self):\n",
    "        print \"Timeout...\"\n",
    "        return True  # continue to listening\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # create a listener object\n",
    "    listener = CustomStreamListener()\n",
    "    \n",
    "    # connect to db\n",
    "    if _writedb_:\n",
    "        db = SimpleSQLServer(dsn='Twitter', keep_alive=True)\n",
    "\n",
    "    if _online_:    \n",
    "        # create an auth object\n",
    "        auth = tweepy.OAuthHandler(config.consumer_key, config.consumer_secret)\n",
    "        auth.set_access_token(config.oauth_token, config.oauth_token_secret)\n",
    "            \n",
    "        # attach the listener object to twitter stream\n",
    "        stream = tweepy.streaming.Stream(auth, listener)\n",
    "        stream.filter(track=['#GameofThrones'])    \n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                if stream.running is False:\n",
    "                    print 'Stream stopped!'\n",
    "                    break\n",
    "                time.sleep(1) # sleep for 1 sec\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "                \n",
    "        stream.disconnect()\n",
    "        db.end\n",
    "        print 'Bye!'\n",
    "    else:\n",
    "        # offline mode\n",
    "        print \"offline mode\" \n",
    "        listener.on_data(utils.read_file('debug/tweet_example_entities.txt'))\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
